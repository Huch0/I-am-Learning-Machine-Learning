# Mining Association Rules

## Introduction

- **Association rule mining** is a data mining technique that discovers interesting relationships or associations among a large set of data items.
- It is used to identify patterns, correlations, and associations in transactional and relational databases.
- Association rule mining is commonly used in **market basket analysis**, **cross-marketing**, and **catalog design**.

## Terminology

- **Itemset**: A collection of one or more items.
- **Transaction**: A record that contains a set of items.
- **Support**: The proportion of transactions that contain a particular itemset.
- **Confidence**: The conditional probability that a transaction contains a particular itemset given that it contains another itemset.
- **Association Rule**: An implication of the form $X \rightarrow Y$, where $X$ and $Y$ are itemsets.

## Key Concepts

- **Frequent Itemset**: An itemset whose support is greater than a specified threshold.
- **Frequent Itemset Mining**: The process of discovering all itemsets that have a support greater than a specified threshold.
- **Apriori Algorithm**: A classic algorithm for frequent itemset mining that uses a level-wise approach to discover frequent itemsets.
- **Association Rule Generation**: The process of generating association rules from frequent itemsets based on a specified confidence threshold.

## Apriori Algorithm

- The **Apriori algorithm** is a classic algorithm for frequent itemset mining in transactional databases.
- It uses a level-wise approach to discover all itemsets that have a support greater than a specified threshold.
- The algorithm consists of two main steps: **frequent itemset generation** and **association rule generation**.

### Frequent Itemset Generation

1. **Candidate Generation**:
    - The Apriori algorithm starts by generating candidate 1-itemsets by scanning the database to find the support of each item.
    - It then uses the support values to prune infrequent itemsets and generate candidate 2-itemsets.
    - This process is repeated to generate candidate k-itemsets until no more frequent itemsets can be found.

2. **Support Counting**:
    - The algorithm scans the database to count the support of each candidate itemset.
    - It uses the support counts to identify frequent itemsets that have a support greater than the specified threshold.

### Association Rule Generation

1. **Rule Generation**:
    - The Apriori algorithm generates association rules from the frequent itemsets based on a specified confidence threshold.
    - It uses the frequent itemsets to generate all possible association rules and calculates the confidence of each rule.

2. **Rule Pruning**:
    - The algorithm prunes association rules that do not meet the specified confidence threshold.
    - It retains only the rules that satisfy the minimum confidence requirement.

## Example

- Let's consider an example to understand how the Apriori algorithm works. Suppose we have a transactional database that contains the following transactions:

```plaintext
    {bread, milk}
    {bread, butter, milk}
    {bread, butter}
    {bread, butter, cheese}
    {butter, cheese}
    {butter, milk}
    {butter, milk, cheese}
    {milk, cheese}
```

- The goal is to discover all frequent itemsets and generate association rules with a minimum support of 30% and a minimum confidence of 60%.

- The Apriori algorithm works as follows:

    1. **Frequent Itemset Generation**:
        - The algorithm starts by generating candidate 1-itemsets and counting their support.
        - It then uses the support counts to identify frequent 1-itemsets.
        - Next, it generates candidate 2-itemsets and counts their support.
        - It uses the support counts to identify frequent 2-itemsets.
        - This process is repeated to generate frequent 3-itemsets and identify all frequent itemsets.

    2. **Association Rule Generation**:
        - The algorithm generates association rules from the frequent itemsets and calculates the confidence of each rule.
        - It prunes rules that do not meet the specified confidence threshold and retains only the rules that satisfy the minimum confidence requirement.

- The Apriori algorithm discovers the following frequent itemsets and association rules:

- **Frequent Itemsets**:
  - {bread}
  - {butter}
  - {milk}
  - {cheese}
  - {bread, butter}
  - {butter, milk}
  - {butter, cheese}
  - {milk, cheese}
  - {butter, milk, cheese}

- **Association Rules**:
  - {bread} -> {butter}
  - {butter} -> {bread}
  - {butter} -> {milk}
  - {milk} -> {butter}
  - {butter} -> {cheese}
  - {cheese} -> {butter}
  - {milk} -> {cheese}
  - {cheese} -> {milk}
  - {butter, milk} -> {cheese}
  - {butter, cheese} -> {milk}
  - {milk, cheese} -> {butter}
