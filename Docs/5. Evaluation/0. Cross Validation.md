# Cross Validation

## Introduction

- **Cross-validation** is a statistical method used to estimate the performance of a predictive model by partitioning the data into subsets and evaluating it on multiple sub-samples.
- It is a popular technique for assessing the generalization ability of a model and reducing the risk of overfitting.
- Cross-validation is widely used in **machine learning**, **statistics**, and **data mining** to compare and select models, and to validate the predictive performance of a model on new data.

## Types of Cross-Validation

1. **K-Fold Cross-Validation**:
    - The data is divided into $k$ subsets of equal size.
    - The model is trained on $k-1$ subsets and tested on the remaining subset.
    - This process is repeated $k$ times, with each subset used as the test set exactly once.
    - The performance of the model is then averaged over the $k$ iterations to obtain the final estimate.

2. **Leave-One-Out Cross-Validation (LOOCV)**:
    - Each observation in the data is used as the test set, and the model is trained on the remaining $n-1$ observations.
    - This process is repeated $n$ times, with each observation used as the test set exactly once.
    - The performance of the model is then averaged over the $n$ iterations to obtain the final estimate.

3. **Stratified K-Fold Cross-Validation**:
    - This method is similar to k-fold cross-validation, but it ensures that each fold is representative of the whole dataset.
    - It is particularly useful for imbalanced datasets where the target variable has a skewed distribution.

4. **Repeated K-Fold Cross-Validation**:
    - The k-fold cross-validation process is repeated multiple times with different random splits of the data.
    - This helps to reduce the variance of the estimated performance and obtain a more reliable estimate of the model's generalization ability.
